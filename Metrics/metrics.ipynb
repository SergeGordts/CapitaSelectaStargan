{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efeb23b3-6940-41c3-967b-3604805fcbcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import math\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93796889-fa8a-4e0d-9afc-d147b52c86f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved model\n",
    "model = tf.keras.models.load_model('./tf-gpu/my_model_finetuned.h5')\n",
    "\n",
    "column_names = ['image_id'] + [\n",
    "    \"5_o_Clock_Shadow\", \"Arched_Eyebrows\", \"Attractive\", \"Bags_Under_Eyes\", \"Bald\", \"Bangs\",\n",
    "    \"Big_Lips\", \"Big_Nose\", \"Black_Hair\", \"Blond_Hair\", \"Blurry\", \"Brown_Hair\", \"Bushy_Eyebrows\",\n",
    "    \"Chubby\", \"Double_Chin\", \"Eyeglasses\", \"Goatee\", \"Gray_Hair\", \"Heavy_Makeup\", \"High_Cheekbones\",\n",
    "    \"Male\", \"Mouth_Slightly_Open\", \"Mustache\", \"Narrow_Eyes\", \"No_Beard\", \"Oval_Face\", \"Pale_Skin\",\n",
    "    \"Pointy_Nose\", \"Receding_Hairline\", \"Rosy_Cheeks\", \"Sideburns\", \"Smiling\", \"Straight_Hair\",\n",
    "    \"Wavy_Hair\", \"Wearing_Earrings\", \"Wearing_Hat\", \"Wearing_Lipstick\", \"Wearing_Necklace\",\n",
    "    \"Wearing_Necktie\", \"Young\"\n",
    "]\n",
    "\n",
    "# Define a function to preprocess the input image\n",
    "def preprocess_image(img_path):\n",
    "    img = image.load_img(img_path, target_size=(128, 128))  # Resize the image\n",
    "    img_array = image.img_to_array(img)  # Convert the image to a numpy array\n",
    "    img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
    "    img_array = img_array / 255.0  # Normalize to [0, 1]\n",
    "    return img_array\n",
    "\n",
    "# Define categories\n",
    "categories = ['Black_Hair', 'Blond_Hair', 'Brown_Hair', 'Male', 'Young']\n",
    "\n",
    "#definition to get predictions for images in specified dir\n",
    "def update_predictions(image_directory, verbose=False):\n",
    "    # Create an empty list to store the results for 'Blond hair' and 'Young'\n",
    "    results = []\n",
    "    images_without_blond_hair = []  \n",
    "    images_not_young = []  \n",
    "    \n",
    "    # Loop over each image in the directory and make predictions\n",
    "    for img_filename in os.listdir(image_directory):\n",
    "        if img_filename.endswith(('.png', '.jpg', '.jpeg')):\n",
    "            img_path = os.path.join(image_directory, img_filename)\n",
    "            \n",
    "            # Preprocess the image\n",
    "            img = preprocess_image(img_path)\n",
    "            \n",
    "            # Get predictions from the model\n",
    "            predictions = model.predict(img,verbose=0)  # This will be a 2D array (1, 5), corresponding to the 5 categories\n",
    "            \n",
    "            # Translate predictions to dataframe values\n",
    "            young_pred = predictions[0][4]  # Prediction for 'Young'\n",
    "            \n",
    "            # Determine Male and Young values based on threshold\n",
    "            young_value = 1 if young_pred > 0.5 else -1\n",
    "            \n",
    "            # Find the index of the highest hair color prediction\n",
    "            hair_predictions = predictions[0][:3]  # First three predictions correspond to hair colors (Black, Blond, Brown)\n",
    "            max_hair_index = np.argmax(hair_predictions)  # Get the index of the highest prediction\n",
    "            if max_hair_index == 1:\n",
    "                blond_value = 1  # Blond hair is set to 1\n",
    "            else:\n",
    "                blond_value = -1\n",
    "            \n",
    "            # Append the prediction results to the list\n",
    "            results.append([img_filename, blond_value, young_value])\n",
    "\n",
    "            # store image paths\n",
    "            if blond_value == -1:\n",
    "                images_without_blond_hair.append(img_path)\n",
    "            if young_value == -1:\n",
    "                images_not_young.append(img_path)\n",
    "                \n",
    "            # Optionally print the progress if verbose=True\n",
    "            if verbose:\n",
    "                print(f\"Processed: {img_filename} | Blond hair: {blond_value}, Young: {young_value}\")\n",
    "    \n",
    "    # Create a DataFrame with the results\n",
    "    df = pd.DataFrame(results, columns=['Image Filename', 'Blond hair', 'Young'])\n",
    "    \n",
    "    # Return the DataFrame with the predictions\n",
    "    return df, images_without_blond_hair, images_not_young\n",
    "\n",
    "\n",
    "# Function to display images in a grid (5 images per row)\n",
    "def display_images(images_paths):\n",
    "    # Number of images per row\n",
    "    images_per_row = 5\n",
    "    num_images = len(images_paths)\n",
    "    \n",
    "    # Calculate number of rows needed to display all images\n",
    "    num_rows = math.ceil(num_images / images_per_row)\n",
    "    \n",
    "    # Create a figure for the grid\n",
    "    fig, axes = plt.subplots(num_rows, images_per_row, figsize=(images_per_row * 3, num_rows * 3))\n",
    "    \n",
    "    # Flatten the axes array to make indexing easier\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    # Loop over each image and display it in the grid\n",
    "    for i, img_path in enumerate(images_paths):\n",
    "        img = mpimg.imread(img_path)\n",
    "        axes[i].imshow(img)\n",
    "        axes[i].axis('off')  # Hide axes for better display\n",
    "    \n",
    "    # Hide any unused axes\n",
    "    for j in range(i + 1, len(axes)):\n",
    "        axes[j].axis('off')\n",
    "    \n",
    "    # Adjust the layout to prevent overlap\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19cbc28d-d4cb-4a44-9f4d-0e44f5209b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#accuracy for CelebA single transformation\n",
    "#normally this is the number correct predictions made by the classifier. \n",
    "#Here the expected output for all images is \"blond hair,\" and the classifier's prediction for each image is compared to this expected output.\n",
    "# accuracy = Number of correct predictions/Total number of predictions\n",
    "\n",
    "# Call the update_predictions function to get the DataFrame\n",
    "df_filtered, CelebA_ST_images_without_blond_hair, _  = update_predictions(\"./celeba_Orig/reduced/images/single transformation/images\", verbose=False)\n",
    "\n",
    "# Count the number of items (rows) in the DataFrame\n",
    "item_count = len(df_filtered)\n",
    "\n",
    "# Print the count\n",
    "print(f\"Number of items in df_filtered: {item_count}\")\n",
    "\n",
    "# Compare the predicted attribute ('Blond_hair') with the expected attribute\n",
    "correct_predictions = df_filtered['Blond hair'] == 1  \n",
    "correct_count = correct_predictions.sum()  # Sum up all True values (1's)\n",
    "\n",
    "# Print the count of correct predictions\n",
    "print(f\"Number of correct predictions: {correct_count}\")\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = correct_predictions.mean()\n",
    "\n",
    "# Print the accuracy\n",
    "print(f'Accuracy: {accuracy * 100:.2f}%')\n",
    "\n",
    "#print images\n",
    "#display_images(CelebA_ST_images_without_blond_hair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc36720b-bab1-4a5d-a37a-e72e398346d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#accuracy for FFHQ single transformation\n",
    "\n",
    "# Call the update_predictions function to get the DataFrame\n",
    "df_filtered, FFHQ_ST_images_without_blond_hair, _  = update_predictions(\"./ffhq/reduced/images/single transformation/images\",verbose=False)\n",
    "\n",
    "# Count the number of items (rows) in the DataFrame\n",
    "item_count = len(df_filtered)\n",
    "\n",
    "# Print the count\n",
    "print(f\"Number of items in df_filtered: {item_count}\")\n",
    "\n",
    "# Compare the predicted attribute ('Blond_hair') with the expected attribute\n",
    "correct_predictions = df_filtered['Blond hair'] == 1  \n",
    "correct_count = correct_predictions.sum()  # Sum up all True values (1's)\n",
    "\n",
    "# Print the count of correct predictions\n",
    "print(f\"Number of correct predictions: {correct_count}\")\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = correct_predictions.mean()\n",
    "\n",
    "# Print the accuracy\n",
    "print(f'Accuracy: {accuracy * 100:.2f}%')\n",
    "\n",
    "#print images\n",
    "#display_images(FFHQ_ST_images_without_blond_hair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ebf0e5-bb93-46dc-80a7-240b31499c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "#accuracy for CelebA multi transformation\n",
    "\n",
    "# Call the update_predictions function to get the DataFrame\n",
    "df_filtered,CelebA_MT_images_without_blond_hair,CelebA_MT_images_without_blond_hair = update_predictions(\"./celeba_Orig/reduced/images/multi transformation/images\", verbose=False)\n",
    "\n",
    "# Print the count\n",
    "print(f\"Number of items in df_filtered: {item_count}\")\n",
    "\n",
    "# Expected values are 1 for both \"Blond hair\" and \"Young\"\n",
    "# Compare both predicted attributes ('Blond_hair' and 'Young') with the expected value\n",
    "# creation of two boolean Series\n",
    "correct_predictions_blond = df_filtered['Blond hair'] == 1   # Blond hair expected to be 1\n",
    "correct_predictions_young = df_filtered['Young'] == 1        # Young expected to be 1\n",
    "\n",
    "# Calculate accuracy for both Blond hair and Young being correctly predicted\n",
    "correct_predictions = correct_predictions_blond & correct_predictions_young\n",
    "correct_count = correct_predictions.sum()  # Sum up all True values (1's)\n",
    "\n",
    "# Print the count of correct predictions\n",
    "print(f\"Number of correct predictions: {correct_count}\")\n",
    "\n",
    "# Calculate overall accuracy\n",
    "accuracy = correct_predictions.mean()\n",
    "\n",
    "# Print the accuracy\n",
    "print(f'Accuracy: {accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b756350c-1885-451c-9e43-6802120a8786",
   "metadata": {},
   "outputs": [],
   "source": [
    "#accuracy for ffhq multi transformation\n",
    "\n",
    "# Call the update_predictions function to get the DataFrame\n",
    "df_filtered,FFHQ_MT_images_without_blond_hair,FFHQ_MT_images_without_blond_hair = update_predictions(\"./ffhq/reduced/images/multi transformation/images\", verbose=False)\n",
    "\n",
    "# Print the count\n",
    "print(f\"Number of items in df_filtered: {item_count}\")\n",
    "\n",
    "# Expected values are 1 for both \"Blond hair\" and \"Young\"\n",
    "# Compare both predicted attributes ('Blond_hair' and 'Young') with the expected value\n",
    "# creation of two boolean Series\n",
    "correct_predictions_blond = df_filtered['Blond hair'] == 1   # Blond hair expected to be 1\n",
    "correct_predictions_young = df_filtered['Young'] == 1        # Young expected to be 1\n",
    "\n",
    "# Calculate accuracy for both Blond hair and Young being correctly predicted\n",
    "correct_predictions = correct_predictions_blond & correct_predictions_young\n",
    "correct_count = correct_predictions.sum()  # Sum up all True values (1's)\n",
    "\n",
    "# Print the count of correct predictions\n",
    "print(f\"Number of correct predictions: {correct_count}\")\n",
    "\n",
    "# Calculate overall accuracy -  computes the proportion of True values in the correct_predictions series\n",
    "accuracy = correct_predictions.mean()\n",
    "\n",
    "# Print the accuracy\n",
    "print(f'Accuracy: {accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510065cd-ca94-4aeb-b55a-7ec8ab25b40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#accuracy side by side\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# Define the accuracy results\n",
    "data = {\n",
    "    'Transformation': ['CelebA Single', 'FFHQ Single', 'CelebA Multi', 'FFHQ Multi'],\n",
    "    'Accuracy (%)': [89.04, 86.44, 75.64, 70.84]  # These should be the accuracy values you calculated\n",
    "}\n",
    "\n",
    "# Create a DataFrame\n",
    "df_accuracy = pd.DataFrame(data)\n",
    "\n",
    "# Plotting the bar chart\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.barplot(x='Transformation', y='Accuracy (%)', data=df_accuracy, palette='Blues_d')\n",
    "plt.title('Accuracy Comparison: CelebA vs FFHQ', fontsize=16)\n",
    "plt.xlabel('Transformation Type', fontsize=14)\n",
    "plt.ylabel('Accuracy (%)', fontsize=14)\n",
    "plt.ylim(0, 100)  # Set y-axis limits from 0 to 100\n",
    "plt.xticks(rotation=45, ha='right')  # Rotate x labels for better readability\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Display the table (this can be included in the paper if needed)\n",
    "print(\"Accuracy Table:\")\n",
    "print(df_accuracy.to_string(index=False))\n",
    "\n",
    "# If you want to save the table to a file\n",
    "df_accuracy.to_csv('accuracy_comparison.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b949f879-a00c-4378-bc82-397459ec93f5",
   "metadata": {},
   "source": [
    "To do: testing generalizability qualitatively through visual inspection of the transformed images, assessing whether the generated attributes are consistent with the intended transformation (blond hair, young).\n",
    "\n",
    "Select Random Samples + and Side-by-Side Comparison (Show the original image alongside the transformed images)\n",
    "Perform Visual Consistency Score: Give each image a score from 1 to 10 based on how well the transformation matches the target attribute (blond hair, young)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
