{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0c1e9f7-8be7-421f-8659-4e64908d0d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,2,3,4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a08db736-2fa8-458c-91fe-c06c774153eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU available\n",
      "CUDA Available: False\n",
      "Error fetching cuDNN version: 'cuda_version'\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Check if a GPU is available\n",
    "gpu_devices = tf.config.list_physical_devices('GPU')\n",
    "if gpu_devices:\n",
    "    print(\"GPU is available!\")\n",
    "    for gpu in gpu_devices:\n",
    "        print(f\"Device: {gpu.name}\")\n",
    "else:\n",
    "    print(\"No GPU available\")\n",
    "\n",
    "# Check if CUDA is available\n",
    "cuda_available = tf.test.is_built_with_cuda()\n",
    "print(f\"CUDA Available: {cuda_available}\")\n",
    "\n",
    "# Check cuDNN version\n",
    "try:\n",
    "    from tensorflow.python.framework import ops\n",
    "    print(f\"cuDNN Version: {tf.sysconfig.get_build_info()['cuda_version']}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error fetching cuDNN version: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ebc0c903-6813-4743-b23c-a962904262c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SHAPE = (128, 128, 3)  # Height, Width, Channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e390b05f-4268-485f-a234-6829dcc84305",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = tf.keras.applications.MobileNetV2(\n",
    "    input_shape=IMG_SHAPE,\n",
    "    include_top=False,\n",
    "    weights='imagenet'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cebb0014-487f-4d71-b863-2b573b7496af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gordts-De Laender\\AppData\\Local\\Temp\\ipykernel_13556\\3508556547.py:10: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  attributes = pd.read_csv(attributes_file, delim_whitespace=True, skiprows=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image batch shape: (64, 128, 128, 3)\n",
      "Label batch shape: (64, 5)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Step 1: Define paths\n",
    "image_dir = \"./celeba_Orig/images/\"\n",
    "attributes_file = \"./celeba_Orig/list_attr_celeba.txt\"\n",
    "\n",
    "# Step 2: Load the attribute file\n",
    "attributes = pd.read_csv(attributes_file, delim_whitespace=True, skiprows=1)\n",
    "attributes.reset_index(inplace=True)  # Reset index to access the filename column\n",
    "attributes.rename(columns={'index': 'image_name'}, inplace=True)\n",
    "\n",
    "# Step 3: Filter for Specific Attributes\n",
    "# Keep only the relevant attributes\n",
    "attributes = attributes[['image_name', 'Black_Hair', 'Blond_Hair', 'Brown_Hair', 'Male', 'Young']]\n",
    "\n",
    "# Step 4: Select a Subset of Images (1/10 of the dataset)\n",
    "subset_fraction = 0.1\n",
    "subset_size = int(len(attributes) * subset_fraction)\n",
    "attributes = attributes.sample(n=subset_size, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Step 5: Define train, test, valid splits\n",
    "# Calculate split sizes based on the subset\n",
    "num_train = int(0.8 * subset_size)  # 80% for training\n",
    "num_valid = int(0.1 * subset_size)  # 10% for validation\n",
    "\n",
    "train_data = attributes[:num_train]\n",
    "valid_data = attributes[num_train:num_train + num_valid]\n",
    "test_data = attributes[num_train + num_valid:]\n",
    "\n",
    "# Step 6: Create a function to load and preprocess images\n",
    "def load_image(img_name, label):\n",
    "    # Ensure img_name is a string by decoding the Tensor\n",
    "    img_name = tf.strings.join([image_dir, img_name])\n",
    "    img = tf.io.read_file(img_name)\n",
    "    img = tf.image.decode_jpeg(img, channels=3)  # Decode JPEG\n",
    "    img = tf.image.resize(img, [128, 128])  # Resize to desired size\n",
    "    img = img / 255.0  # Normalize to [0, 1]\n",
    "    return img, label\n",
    "\n",
    "\n",
    "# Step 7: Create a function to generate a TensorFlow dataset\n",
    "def create_dataset(dataframe):\n",
    "    image_names = dataframe['image_name'].values\n",
    "    labels = dataframe.iloc[:, 1:].values  # All columns except 'image_name'\n",
    "    \n",
    "    # Convert labels from -1,1 to 0,1 (for binary classification)\n",
    "    labels = (labels + 1) // 2  # Convert -1, 1 to 0, 1\n",
    "    \n",
    "    # Labels are already binary (0 or 1), no need for one-hot encoding\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((image_names, labels))\n",
    "    dataset = dataset.map(lambda x, y: load_image(x, y), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    return dataset\n",
    "\n",
    "# Step 8: Create train, test, and validation datasets\n",
    "raw_train = create_dataset(train_data).shuffle(1000).batch(64).prefetch(tf.data.AUTOTUNE)\n",
    "raw_valid = create_dataset(valid_data).batch(64).prefetch(tf.data.AUTOTUNE)\n",
    "raw_test = create_dataset(test_data).batch(64).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "# Step 9: Verify the dataset\n",
    "for images, labels in raw_train.take(1):\n",
    "    print(f\"Image batch shape: {images.shape}\")\n",
    "    print(f\"Label batch shape: {labels.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6473f208-5d21-4631-bd36-616c80655310",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = tf.keras.applications.ResNet50(weights='imagenet', include_top=False, input_shape=(128, 128, 3))\n",
    "base_model.trainable = False\n",
    "\n",
    "global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
    "prediction_layer = tf.keras.layers.Dense(5, activation='sigmoid')  # Use sigmoid for multi-label classification\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "  base_model,\n",
    "  global_average_layer,\n",
    "  prediction_layer\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.0001),\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(from_logits=False),\n",
    "    metrics=[tf.keras.metrics.BinaryAccuracy()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a69601-fb40-4a60-8d6b-c7c55b03d2e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/31 [=======================>......] - ETA: 3s - loss: 0.7688 - binary_accuracy: 0.4614 "
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "import pickle\n",
    "\n",
    "# Define validation steps (can be adjusted as needed)\n",
    "validation_steps = 31 #Number of validation images 2000 /Batch size 64\n",
    "initial_epochs = 20\n",
    "\n",
    "# Define early stopping callback\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',       # Monitor validation loss\n",
    "    patience=3,               # Patience of 3 epochs\n",
    "    restore_best_weights=True # Restore best weights\n",
    ")\n",
    "\n",
    "# Define learning rate scheduler callback\n",
    "lr_scheduler = ReduceLROnPlateau(\n",
    "    monitor='val_loss',      # Monitor validation loss\n",
    "    factor=0.5,              # Reduce learning rate by 50%\n",
    "    patience=2,              # Wait for 2 epochs without improvement before reducing\n",
    "    min_lr=1e-6              # Minimum learning rate to avoid too small learning rate\n",
    ")\n",
    "\n",
    "# Evaluate the model on the validation dataset\n",
    "loss0, accuracy0 = model.evaluate(raw_valid, steps=validation_steps)\n",
    "\n",
    "# Train the model with both callbacks\n",
    "history = model.fit(\n",
    "    raw_train,\n",
    "    epochs=initial_epochs,\n",
    "    validation_data=raw_valid,\n",
    "    callbacks=[early_stopping, lr_scheduler]  # Include both callbacks\n",
    ")\n",
    "\n",
    "# Save the model\n",
    "model.save('my_model.h5')  # Saves the model in HDF5 format\n",
    "\n",
    "# Save history to a file\n",
    "with open('training_history.pkl', 'wb') as f:\n",
    "    pickle.dump(history.history, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ed9b0e-93c3-479e-a0e7-9800f60d7126",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Extract the loss and accuracy history\n",
    "acc = history.history['binary_accuracy']\n",
    "val_acc = history.history['val_binary_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "# Define the number of epochs\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "# Plot Accuracy\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs, acc, 'b', label='Training Accuracy')\n",
    "plt.plot(epochs, val_acc, 'r', label='Validation Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# Plot Loss\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs, loss, 'b', label='Training Loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "# Show the plots\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e21577f-f0f2-4294-9330-9f1934a47b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "# Load the saved model\n",
    "model = tf.keras.models.load_model('my_model.h5')\n",
    "\n",
    "# Define a function to preprocess the input image\n",
    "def preprocess_image(img_path):\n",
    "    img = image.load_img(img_path, target_size=(128, 128))  # Resize the image\n",
    "    img_array = image.img_to_array(img)  # Convert the image to a numpy array\n",
    "    img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
    "    img_array = img_array / 255.0  # Normalize to [0, 1]\n",
    "    return img_array\n",
    "\n",
    "# Define categories\n",
    "categories = ['Black_Hair', 'Blond_Hair', 'Brown_Hair', 'Male', 'Young']\n",
    "\n",
    "# Directory containing images\n",
    "image_directory = '.'  # Replace with the path to your image directory\n",
    "image_paths = [os.path.join(image_directory, fname) for fname in os.listdir(image_directory) if fname.endswith(('.png', '.jpg', '.jpeg'))]\n",
    "\n",
    "# Set up grid size\n",
    "grid_size = 3\n",
    "fig, axes = plt.subplots(grid_size, grid_size, figsize=(15, 15))\n",
    "axes = axes.flatten()  # Flatten axes for easy iteration\n",
    "\n",
    "# Iterate through images and display predictions\n",
    "for i, ax in enumerate(axes):\n",
    "    if i < len(image_paths):\n",
    "        img_path = image_paths[i]\n",
    "        \n",
    "        # Preprocess and predict\n",
    "        img = preprocess_image(img_path)\n",
    "        predictions = model.predict(img)\n",
    "        binary_predictions = (predictions >= 0.5).astype(int)\n",
    "        \n",
    "        # Display image\n",
    "        img_display = image.load_img(img_path, target_size=(128, 128))\n",
    "        ax.imshow(img_display)\n",
    "        ax.axis('off')  # Hide axis\n",
    "        \n",
    "        # Display categories\n",
    "        prediction_text = \", \".join([f\"{cat}: {'Yes' if binary_predictions[0][j] == 1 else 'No'}\" for j, cat in enumerate(categories)])\n",
    "        ax.set_title(prediction_text, fontsize=10)\n",
    "    else:\n",
    "        ax.axis('off')  # Hide any unused grid cells\n",
    "\n",
    "# Adjust layout and display the grid\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097979a6-60b0-493d-a193-44b12319cd15",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
