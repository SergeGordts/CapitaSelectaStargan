{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ee7aac-0850-4788-85d9-71b5c955cedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the directory for a single transformation\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "#place all images from the subdirectories in in ffhq/images - images downloaded from https://github.com/NVlabs/ffhq-dataset\n",
    "source_dir = \"ffhq\" \n",
    "dest_dir = os.path.join(source_dir, \"images\")  # The new directory for copied images\n",
    "    # Create the destination directory if it doesn't exist\n",
    "os.makedirs(dest_dir, exist_ok=True)\n",
    "# Iterate through all subdirectories in the source directory\n",
    "for sub_dir in sorted(os.listdir(source_dir)):\n",
    "    sub_dir_path = os.path.join(source_dir, sub_dir)\n",
    "    if os.path.isdir(sub_dir_path)  and sub_dir != \"images\":\n",
    "        # Iterate through all files in the subdirectory\n",
    "        for file_name in os.listdir(sub_dir_path):\n",
    "            file_path = os.path.join(sub_dir_path, file_name)\n",
    "            if os.path.isfile(file_path):  # Check if it's a file\n",
    "                # Copy the file to the destination directory\n",
    "                shutil.copy(file_path, dest_dir)\n",
    "\n",
    "# Define the base directories\n",
    "base_dir = 'ffhq'\n",
    "images_dir = os.path.join(base_dir, 'images')\n",
    "output_dir = os.path.join(base_dir, 'reduced/images')\n",
    "# Create new directory structure\n",
    "train_dir = os.path.join(output_dir, 'train')\n",
    "test_dir = os.path.join(output_dir, 'test')\n",
    "val_dir = os.path.join(output_dir, 'val')\n",
    "\n",
    "# Create the directories if they do not exist\n",
    "os.makedirs(train_dir, exist_ok=True)\n",
    "os.makedirs(test_dir, exist_ok=True)\n",
    "os.makedirs(val_dir, exist_ok=True)\n",
    "\n",
    "# Get all image files\n",
    "image_files = [f for f in os.listdir(images_dir) if f.endswith('.png')]\n",
    "\n",
    "#Behavior of the Dataset and Loader ==> Preprocessing (preprocess Method): The preprocess method divides the dataset into two parts:\n",
    "# The first 2000 entries go into self.test_dataset. The rest go into self.train_dataset.\n",
    "# This division is fixed and deterministic because the seed for random.shuffle is set using random.seed(1234).\n",
    "num_test_images = 2000 #int(len(image_files) * 0.10)\n",
    "test_images = random.sample(image_files, num_test_images)\n",
    "\n",
    "# Move the images to the test folder\n",
    "for image in test_images:\n",
    "    shutil.copy(os.path.join(images_dir, image), os.path.join(test_dir, image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8904d49e-ffc5-4a2e-9d6d-bd3b7260094b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare list_attr_celeba.txt with labels (all 1) for single transformation\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Define the path to the file\n",
    "file_path = \"celeba_orig/list_attr_celeba.txt\"  # Replace with the actual file path\n",
    "\n",
    "# Read the file starting from the second line, and add 'image_id' as the first column\n",
    "column_names = ['image_id'] + [\n",
    "    \"5_o_Clock_Shadow\", \"Arched_Eyebrows\", \"Attractive\", \"Bags_Under_Eyes\", \"Bald\", \"Bangs\",\n",
    "    \"Big_Lips\", \"Big_Nose\", \"Black_Hair\", \"Blond_Hair\", \"Blurry\", \"Brown_Hair\", \"Bushy_Eyebrows\",\n",
    "    \"Chubby\", \"Double_Chin\", \"Eyeglasses\", \"Goatee\", \"Gray_Hair\", \"Heavy_Makeup\", \"High_Cheekbones\",\n",
    "    \"Male\", \"Mouth_Slightly_Open\", \"Mustache\", \"Narrow_Eyes\", \"No_Beard\", \"Oval_Face\", \"Pale_Skin\",\n",
    "    \"Pointy_Nose\", \"Receding_Hairline\", \"Rosy_Cheeks\", \"Sideburns\", \"Smiling\", \"Straight_Hair\",\n",
    "    \"Wavy_Hair\", \"Wearing_Earrings\", \"Wearing_Hat\", \"Wearing_Lipstick\", \"Wearing_Necklace\",\n",
    "    \"Wearing_Necktie\", \"Young\"\n",
    "]\n",
    "\n",
    "# Read the file, skipping the first line and adding column names\n",
    "df = pd.read_csv(file_path, sep=r'\\s+', header=None, skiprows=2, names=column_names)\n",
    "\n",
    "# Define file paths\n",
    "reduced_images_dir = \"ffhq/reduced/images/test\"\n",
    "reduced_attr_file = \"ffhq/reduced/images/list_attr_celeba.txt\"\n",
    "\n",
    "# Get the list of image filenames in the reduced directory (convert to sorted list)\n",
    "reduced_images = sorted(os.listdir(reduced_images_dir))  # Sort the filenames to maintain order\n",
    "\n",
    "# Limit df to the number of reduced_images (if there are more rows in df than image files)\n",
    "df_filtered = df.head(len(reduced_images))\n",
    "\n",
    "# Ensure that df_filtered has the same length as reduced_images\n",
    "if len(df_filtered) == len(reduced_images):\n",
    "    # Assign the filenames (as sorted list) to the 'image_id' column\n",
    "    df_filtered['image_id'] = reduced_images\n",
    "    # Set all attribute values (columns 1 and onward) to 1\n",
    "    df_filtered.iloc[:, 1:] = 1\n",
    "else:\n",
    "    print(f\"Warning: Number of image files in reduced_images ({len(reduced_images)}) does not match the number of rows in df_filtered ({len(df_filtered)}).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1d944c-01c7-46a5-a8ab-46bc0939f0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: run mobilenet for generation of hair, gender and young labels\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "# Load the saved model\n",
    "model = tf.keras.models.load_model('./tf-gpu/my_model_finetuned.h5')\n",
    "\n",
    "# Define a function to preprocess the input image\n",
    "def preprocess_image(img_path):\n",
    "    img = image.load_img(img_path, target_size=(128, 128))  # Resize the image\n",
    "    img_array = image.img_to_array(img)  # Convert the image to a numpy array\n",
    "    img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
    "    img_array = img_array / 255.0  # Normalize to [0, 1]\n",
    "    return img_array\n",
    "\n",
    "# Define categories\n",
    "categories = ['Black_Hair', 'Blond_Hair', 'Brown_Hair', 'Male', 'Young']\n",
    "\n",
    "# Directory containing images\n",
    "image_directory = './ffhq/reduced/images/test'  # Replace with the path to your image directory\n",
    "\n",
    "# Loop over each image in the directory and make predictions\n",
    "for img_filename in os.listdir(image_directory):\n",
    "    if img_filename.endswith(('.png', '.jpg', '.jpeg')):\n",
    "        img_path = os.path.join(image_directory, img_filename)\n",
    "        \n",
    "        # Preprocess the image\n",
    "        img = preprocess_image(img_path)\n",
    "        \n",
    "        # Get predictions from the model\n",
    "        predictions = model.predict(img)  # This will be a 2D array (1, 5), corresponding to the 5 categories\n",
    "        \n",
    "        # Translate predictions to dataframe values\n",
    "        male_pred = predictions[0][3]  # Prediction for 'Male'\n",
    "        young_pred = predictions[0][4]  # Prediction for 'Young'\n",
    "        \n",
    "        # Determine Male and Young values based on threshold\n",
    "        male_value = 1 if male_pred > 0.5 else -1\n",
    "        young_value = 1 if young_pred > 0.5 else -1\n",
    "        \n",
    "        # Find the index of the highest hair color prediction\n",
    "        hair_predictions = predictions[0][:3]  # First three predictions correspond to hair colors (Black, Blond, Brown)\n",
    "        max_hair_index = np.argmax(hair_predictions)  # Get the index of the highest prediction\n",
    "        hair_values = [-1, -1, -1]  # Initialize all hair color values to -1\n",
    "        hair_values[max_hair_index] = 1  # Set the highest hair color prediction to 1\n",
    "                \n",
    "        # Get the corresponding image_id from df (assuming the image_id matches the img_filename)\n",
    "        image_id = df_filtered.loc[df_filtered['image_id'] == img_filename, 'image_id'].values\n",
    "\n",
    "        if len(image_id) > 0:\n",
    "            # Update df_filtered with the predictions\n",
    "            df_filtered.loc[df_filtered['image_id'] == img_filename, ['Young', 'Male', 'Black_Hair', 'Blond_Hair', 'Brown_Hair']] = [\n",
    "                young_value, male_value, hair_values[0], hair_values[1], hair_values[2]\n",
    "            ]\n",
    "        else:\n",
    "            print(f\"Warning: Image filename {img_filename} not found in df['image_id']!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c31931-36a8-44d0-ae60-a097e1144fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Open the file in write mode\n",
    "with open(reduced_attr_file, 'w') as f:\n",
    "    # Write the number of rows in df_filtered\n",
    "    f.write(f\"{len(df_filtered)}\\n\")\n",
    "    \n",
    "    # Write the column names excluding 'image_id' (join the rest with spaces)\n",
    "    f.write(\" \".join(df_filtered.columns[1:]) + \"\\n\")\n",
    "    \n",
    "    # Write the data in df_filtered (row by row) to avoid extra new lines\n",
    "    for index, row in df_filtered.iterrows():\n",
    "        # Write each row to the file, with space-separated values\n",
    "        f.write(\" \".join(row.astype(str).values[0:]) + \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
