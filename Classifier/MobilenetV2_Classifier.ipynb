{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cebb0014-487f-4d71-b863-2b573b7496af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Step 1: Define paths\n",
    "image_dir = \"./celeba_Orig/images/\"\n",
    "attributes_file = \"./celeba_Orig/list_attr_celeba.txt\"\n",
    "\n",
    "# Step 2: Load the attribute file\n",
    "attributes = pd.read_csv(attributes_file, delim_whitespace=True, skiprows=1)\n",
    "attributes.reset_index(inplace=True)  # Reset index to access the filename column\n",
    "attributes.rename(columns={'index': 'image_name'}, inplace=True)\n",
    "\n",
    "# Step 3: Filter for Specific Attributes\n",
    "# Keep only the relevant attributes\n",
    "attributes = attributes[['image_name', 'Black_Hair', 'Blond_Hair', 'Brown_Hair', 'Male', 'Young']]\n",
    "\n",
    "# Step 4: Select a Subset of Images (2/10 of the dataset)\n",
    "subset_fraction = 0.2\n",
    "subset_size = int(len(attributes) * subset_fraction)\n",
    "attributes = attributes.sample(n=subset_size, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Step 5: Define train, test, valid splits\n",
    "# Calculate split sizes based on the subset\n",
    "num_train = int(0.8 * subset_size)  # 80% for training\n",
    "num_valid = int(0.1 * subset_size)  # 10% for validation\n",
    "\n",
    "train_data = attributes[:num_train]\n",
    "valid_data = attributes[num_train:num_train + num_valid]\n",
    "test_data = attributes[num_train + num_valid:]\n",
    "\n",
    "# Step 6: Create a function to load and preprocess images\n",
    "def load_image(img_name, label):\n",
    "    # Ensure img_name is a string by decoding the Tensor\n",
    "    img_name = tf.strings.join([image_dir, img_name])\n",
    "    img = tf.io.read_file(img_name)\n",
    "    img = tf.image.decode_jpeg(img, channels=3)  # Decode JPEG\n",
    "    # Crop the image to 178x178 from the center\n",
    "    img = tf.image.resize_with_crop_or_pad(img, target_height=178, target_width=178)\n",
    "    \n",
    "    # Resize to 128x128\n",
    "    img = tf.image.resize(img, [128, 128])    \n",
    "    img = img / 255.0  # Normalize to [0, 1]\n",
    "    return img, label\n",
    "\n",
    "\n",
    "# Step 7: Create a function to generate a TensorFlow dataset\n",
    "def create_dataset(dataframe):\n",
    "    image_names = dataframe['image_name'].values\n",
    "    labels = dataframe.iloc[:, 1:].values  # All columns except 'image_name'\n",
    "    \n",
    "    # Convert labels from -1,1 to 0,1 (for binary classification)\n",
    "    labels = (labels + 1) // 2  # Convert -1, 1 to 0, 1\n",
    "    \n",
    "    # Labels are already binary (0 or 1), no need for one-hot encoding\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((image_names, labels))\n",
    "    dataset = dataset.map(lambda x, y: load_image(x, y), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    dataset = dataset.repeat()  # Add this line to repeat the dataset indefinitely\n",
    "    return dataset\n",
    "\n",
    "# Step 8: Create train, test, and validation datasets\n",
    "raw_train = create_dataset(train_data).shuffle(1000).batch(128).prefetch(tf.data.AUTOTUNE)\n",
    "raw_valid = create_dataset(valid_data).batch(128).prefetch(tf.data.AUTOTUNE)\n",
    "raw_test = create_dataset(test_data).batch(128).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "# Step 9: Verify the dataset\n",
    "for images, labels in raw_train.take(1):\n",
    "    print(f\"Image batch shape: {images.shape}\")\n",
    "    print(f\"Label batch shape: {labels.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6473f208-5d21-4631-bd36-616c80655310",
   "metadata": {},
   "outputs": [],
   "source": [
    "#base_model = tf.keras.applications.ResNet50(weights='imagenet', include_top=False, input_shape=(128, 128, 3))\n",
    "import tensorflow as tf\n",
    "base_model = tf.keras.applications.MobileNetV2(\n",
    "    include_top=False,\n",
    "    weights='imagenet',\n",
    "    input_shape=(128, 128, 3)\n",
    ")\n",
    "\n",
    "base_model.trainable = False\n",
    "\n",
    "global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
    "prediction_layer = tf.keras.layers.Dense(5, activation='sigmoid')  # Use sigmoid for multi-label classification\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "  base_model,\n",
    "  global_average_layer,\n",
    "  prediction_layer\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.0001),\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(from_logits=False),\n",
    "    metrics=[tf.keras.metrics.BinaryAccuracy()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a69601-fb40-4a60-8d6b-c7c55b03d2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "import pickle\n",
    "\n",
    "# Define validation steps (can be adjusted as needed)\n",
    "validation_steps = 34 #Number of validation images /Batch size\n",
    "initial_epochs = 40\n",
    "steps_per_epoch = 275\n",
    "\n",
    "# Define early stopping callback\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',       # Monitor validation loss\n",
    "    patience=3,               # Patience of 3 epochs\n",
    "    restore_best_weights=True # Restore best weights\n",
    ")\n",
    "\n",
    "# Define learning rate scheduler callback\n",
    "lr_scheduler = ReduceLROnPlateau(\n",
    "    monitor='val_loss',      # Monitor validation loss\n",
    "    factor=0.5,              # Reduce learning rate by 50%\n",
    "    patience=2,              # Wait for 2 epochs without improvement before reducing\n",
    "    min_lr=1e-6              # Minimum learning rate to avoid too small learning rate\n",
    ")\n",
    "\n",
    "# Evaluate the model on the validation dataset\n",
    "loss0, accuracy0 = model.evaluate(raw_valid, steps=validation_steps)\n",
    "\n",
    "# Train the model with both callbacks\n",
    "history = model.fit(\n",
    "    raw_train,\n",
    "    epochs=initial_epochs,\n",
    "    steps_per_epoch=steps_per_epoch, \n",
    "    validation_steps=validation_steps,\n",
    "    validation_data=raw_valid,\n",
    "    callbacks=[early_stopping, lr_scheduler]  # Include both callbacks\n",
    ")\n",
    "\n",
    "# Save the model\n",
    "model.save('my_model.h5')  # Saves the model in HDF5 format\n",
    "\n",
    "# Save history to a file\n",
    "with open('training_history.pkl', 'wb') as f:\n",
    "    pickle.dump(history.history, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ed9b0e-93c3-479e-a0e7-9800f60d7126",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "# Load the history dictionary\n",
    "with open('training_history.pkl', 'rb') as f:\n",
    "    history_dict = pickle.load(f)\n",
    "\n",
    "# Extract the loss and accuracy history\n",
    "acc = history_dict['binary_accuracy']\n",
    "val_acc = history_dict['val_binary_accuracy']\n",
    "loss = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "\n",
    "# Define the number of epochs\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "# Plot Accuracy\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs, acc, 'b', label='Training Accuracy')\n",
    "plt.plot(epochs, val_acc, 'r', label='Validation Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# Plot Loss\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs, loss, 'b', label='Training Loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "# Show the plots\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e21577f-f0f2-4294-9330-9f1934a47b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "# Load the saved model\n",
    "model = tf.keras.models.load_model('my_model.h5')\n",
    "\n",
    "# Define a function to preprocess the input image\n",
    "def preprocess_image(img_path):\n",
    "    img = image.load_img(img_path, target_size=(128, 128))  # Resize the image\n",
    "    img_array = image.img_to_array(img)  # Convert the image to a numpy array\n",
    "    img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
    "    img_array = img_array / 255.0  # Normalize to [0, 1]\n",
    "    return img_array\n",
    "\n",
    "# Define categories\n",
    "categories = ['Black_Hair', 'Blond_Hair', 'Brown_Hair', 'Male', 'Young']\n",
    "\n",
    "# Directory containing images\n",
    "image_directory = '.'  # Replace with the path to your image directory\n",
    "image_paths = [os.path.join(image_directory, fname) for fname in os.listdir(image_directory) if fname.endswith(('.png', '.jpg', '.jpeg'))]\n",
    "\n",
    "# Set up grid size with 2 images per row (adjusting for the number of images)\n",
    "images_per_row = 2\n",
    "grid_size = (len(image_paths) // images_per_row) + (1 if len(image_paths) % images_per_row != 0 else 0)\n",
    "fig, axes = plt.subplots(grid_size, images_per_row, figsize=(15, grid_size * 7))\n",
    "axes = axes.flatten()  # Flatten axes for easy iteration\n",
    "\n",
    "# Define threshold to classify the predictions as Yes/No\n",
    "threshold = 0.5\n",
    "\n",
    "# Iterate through images and display predictions\n",
    "for i, ax in enumerate(axes):\n",
    "    if i < len(image_paths):\n",
    "        img_path = image_paths[i]\n",
    "        \n",
    "        # Preprocess and predict\n",
    "        img = preprocess_image(img_path)\n",
    "        predictions = model.predict(img)  # Get raw model predictions\n",
    "        \n",
    "        # Display image\n",
    "        img_display = image.load_img(img_path, target_size=(128, 128))\n",
    "        ax.imshow(img_display)\n",
    "        ax.axis('off')  # Hide axis\n",
    "        \n",
    "        # Display categories with prediction percentages\n",
    "        prediction_text = \", \".join([f\"{cat}: {predictions[0][j]*100:.2f}%\" for j, cat in enumerate(categories)])\n",
    "        \n",
    "        # Convert predictions to Yes/No based on threshold\n",
    "        #prediction_text = \", \".join([f\"{cat}: {'Yes' if predictions[0][j] >= threshold else 'No'}\" for j, cat in enumerate(categories)])\n",
    "        ax.set_title(prediction_text, fontsize=10)\n",
    "    else:\n",
    "        ax.axis('off')  # Hide any unused grid cells\n",
    "\n",
    "# Adjust layout and display the grid\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097979a6-60b0-493d-a193-44b12319cd15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "import pickle\n",
    "\n",
    "# Load the pre-trained model from the saved file\n",
    "model = tf.keras.models.load_model('my_model.h5')  \n",
    "\n",
    "# Define validation steps \n",
    "validation_steps = 34 #Number of validation images /Batch size\n",
    "initial_epochs = 40\n",
    "steps_per_epoch = 275\n",
    "\n",
    "# Set the base model to be trainable\n",
    "base_model = model.layers[0]  # The first layer should be the MobileNetV2 base model\n",
    "base_model.trainable = True\n",
    "\n",
    "# Print the number of layers in the base model to understand where to unfreeze\n",
    "print(\"Number of layers in the base model: \", len(base_model.layers))\n",
    "\n",
    "# Fine-tune from this layer onwards \n",
    "fine_tune_at = 100\n",
    "\n",
    "# Freeze all the layers before the `fine_tune_at` layer\n",
    "for layer in base_model.layers[:fine_tune_at]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Recompile the model after unfreezing some layers\n",
    "model.compile(\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(from_logits=False),  \n",
    "    optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.00001),  \n",
    "    metrics=[tf.keras.metrics.BinaryAccuracy()]\n",
    ")\n",
    "\n",
    "# Load the history dictionary\n",
    "with open('training_history.pkl', 'rb') as f:\n",
    "    history_dict = pickle.load(f)\n",
    "\n",
    "initial_epoch = len(history_dict['loss'])\n",
    "\n",
    "# Define the number of epochs for fine-tuning\n",
    "fine_tune_epochs = 10\n",
    "total_epochs = initial_epochs + fine_tune_epochs  # Total epochs include the initial training and fine-tuning\n",
    "\n",
    "# Define early stopping callback\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',       # Monitor validation loss\n",
    "    patience=3,               # Patience of 3 epochs\n",
    "    restore_best_weights=True # Restore best weights\n",
    ")\n",
    "\n",
    "# Define learning rate scheduler callback\n",
    "lr_scheduler = ReduceLROnPlateau(\n",
    "    monitor='val_loss',      # Monitor validation loss\n",
    "    factor=0.5,              # Reduce learning rate by 50%\n",
    "    patience=2,              # Wait for 2 epochs without improvement before reducing\n",
    "    min_lr=1e-6              # Minimum learning rate to avoid too small learning rate\n",
    ")\n",
    "\n",
    "# Evaluate the model on the validation dataset\n",
    "loss0, accuracy0 = model.evaluate(raw_valid, steps=validation_steps)\n",
    "\n",
    "# Fine-tune the model\n",
    "history_fine = model.fit(\n",
    "    raw_train,  # Training dataset\n",
    "    epochs=total_epochs,\n",
    "    initial_epoch=initial_epoch,  # Continue from the last epoch of initial training\n",
    "    validation_data=raw_valid,  # Validation dataset\n",
    "    steps_per_epoch=steps_per_epoch,  # Steps per epoch during fine-tuning\n",
    "    validation_steps=validation_steps,  # Validation steps\n",
    "    callbacks=[early_stopping, lr_scheduler]  \n",
    ")\n",
    "\n",
    "# Save the fine-tuned model\n",
    "model.save('my_model_finetuned.h5')  # Saves the fine-tuned model in HDF5 format\n",
    "\n",
    "# Save history of fine-tuning to a file\n",
    "with open('training_history_fine.pkl', 'wb') as f:\n",
    "    pickle.dump(history_fine.history, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba24471-b9c9-4bc4-998f-d95f810b59d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "# Load the history dictionary\n",
    "with open('training_history_fine.pkl', 'rb') as f:\n",
    "    history_dict = pickle.load(f)\n",
    "\n",
    "# Extract the loss and accuracy history\n",
    "acc = history_dict['binary_accuracy']\n",
    "val_acc = history_dict['val_binary_accuracy']\n",
    "loss = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "\n",
    "# Define the number of epochs\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "# Plot Accuracy\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs, acc, 'b', label='Training Accuracy')\n",
    "plt.plot(epochs, val_acc, 'r', label='Validation Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# Plot Loss\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs, loss, 'b', label='Training Loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "# Show the plots\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658d7e08-b824-47cb-9c2e-b4dfc8cfa809",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "# Load the saved model\n",
    "model = tf.keras.models.load_model('my_model_finetuned.h5')\n",
    "\n",
    "# Define a function to preprocess the input image\n",
    "def preprocess_image(img_path):\n",
    "    img = image.load_img(img_path, target_size=(128, 128))  # Resize the image\n",
    "    img_array = image.img_to_array(img)  # Convert the image to a numpy array\n",
    "    img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
    "    img_array = img_array / 255.0  # Normalize to [0, 1]\n",
    "    return img_array\n",
    "\n",
    "# Define categories\n",
    "categories = ['Black_Hair', 'Blond_Hair', 'Brown_Hair', 'Male', 'Young']\n",
    "\n",
    "# Directory containing images\n",
    "image_directory = '.'  \n",
    "image_paths = [os.path.join(image_directory, fname) for fname in os.listdir(image_directory) if fname.endswith(('.png', '.jpg', '.jpeg'))]\n",
    "\n",
    "# Set up grid size with 2 images per row (adjusting for the number of images)\n",
    "images_per_row = 2\n",
    "grid_size = (len(image_paths) // images_per_row) + (1 if len(image_paths) % images_per_row != 0 else 0)\n",
    "fig, axes = plt.subplots(grid_size, images_per_row, figsize=(15, grid_size * 7))\n",
    "axes = axes.flatten()  # Flatten axes for easy iteration\n",
    "\n",
    "# Define threshold to classify the predictions as Yes/No\n",
    "threshold = 0.5\n",
    "\n",
    "# Iterate through images and display predictions\n",
    "for i, ax in enumerate(axes):\n",
    "    if i < len(image_paths):\n",
    "        img_path = image_paths[i]\n",
    "        \n",
    "        # Preprocess and predict\n",
    "        img = preprocess_image(img_path)\n",
    "        predictions = model.predict(img)  # Get raw model predictions\n",
    "        \n",
    "        # Display image\n",
    "        img_display = image.load_img(img_path, target_size=(128, 128))\n",
    "        ax.imshow(img_display)\n",
    "        ax.axis('off')  # Hide axis\n",
    "        \n",
    "        # Display categories with prediction percentages\n",
    "        prediction_text = \", \".join([f\"{cat}: {predictions[0][j]*100:.2f}%\" for j, cat in enumerate(categories)])\n",
    "        \n",
    "        ax.set_title(prediction_text, fontsize=10)\n",
    "    else:\n",
    "        ax.axis('off')  # Hide any unused grid cells\n",
    "\n",
    "# Adjust layout and display the grid\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a017c58e-ff6e-415e-b4db-6415f7f838c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
